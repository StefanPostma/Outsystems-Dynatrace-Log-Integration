#----------------------------------------------------------------------------------------------------
# Information
#----------------------------------------------------------------------------------------------------
# This file is supposed to hold environment variables that will be used in Logstash pipelines.
# It's a way of abstracting details from the pipelines themselves.
# Some of the variables already have sensible defaults.
#
# Please check and copy your current configuration variables and add those into this template to NOT break your current Logstash configuration
# For Red Hat based distros: cat /etc/sysconfig/logstash
# For Debian based distros: cat /etc/default/logstash
#----------------------------------------------------------------------------------------------------
# Current Settings
#----------------------------------------------------------------------------------------------------
#
#
#
#
#
#----------------------------------------------------------------------------------------------------
#
# Important!
# This file must be saved in "/etc/sysconfig" folder with the name "logstash". After that it must
# have at least "600" permissions (use chmod for this setting).
#
#----------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------
# MonitorProbe Settings - Needed for Monitor Probe pipelines
#----------------------------------------------------------------------------------------------------
# MP_BASE_URL: MonitorProbe base URL. Something like https://outsystems-production-domain.com/MonitorProbe/rest/PlatformLogs/.
# MP_USER: The username to access the MonitorProbe API.
# MP_PASSWORD: The password to access the MonitorProbe API.
# MP_INTERVAL: The interval of data to fetch (last N minutes).
# MP_SCHEDULE: Schedule of when to periodically poll from the MonitorProbe API.
#              See official documentation here: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-http_poller.html#plugins-inputs-http_poller-schedule
# MP_REQUEST_TIMEOUT: Timeout waiting for response in full.
#                     See official documentation here: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-http_poller.html#plugins-inputs-http_poller-request_timeout
# MP_SOCKET_TIMEOUT: Timeout waiting for the first data chunk of the response.
#                    See official documentation here: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-http_poller.html#plugins-inputs-http_poller-socket_timeout
#----------------------------------------------------------------------------------------------------
MP_BASE_URL=""
MP_USER=""
MP_PASSWORD=""
MP_INTERVAL="3"
MP_SCHEDULE="2m"
MP_REQUEST_TIMEOUT="120"
MP_SOCKET_TIMEOUT="60"

#----------------------------------------------------------------------------------------------------
# JDBC Settings - Needed for Database pipelines
#----------------------------------------------------------------------------------------------------
# JDBC_LIBRARY: The full path for the JDBC Driver. Something like /usr/share/logstash/logstash-core/lib/jars/mssql-jdbc-12.4.2.jre11.jar
# JDBC_DRIVER_CLASS: The full class name of the JDBC driver.
# JDBC_CONNECTION_STRING: The connection string to SQL Server database. Something like jdbc:sqlserver://<SERVER>:1433;database=<LOG_DATABASE>;loginTimeout=30;
# JDBC_USER: The username to access the database.
# JDBC_PASSWORD: The password to access the database.
# JDBC_SCHEDULE: The schedule to poll the database for data. It is a Crontab-like expression.
#----------------------------------------------------------------------------------------------------
JDBC_LIBRARY=""
JDBC_DRIVER_CLASS="com.microsoft.sqlserver.jdbc.SQLServerDriver"
JDBC_CONNECTION_STRING=""
JDBC_USER=""
JDBC_PASSWORD=""
JDBC_SCHEDULE="*/5 * * * *"

#----------------------------------------------------------------------------------------------------
# Data Settings
#----------------------------------------------------------------------------------------------------
# LAST_RUN_PATH: The full path to a directory to store files with last runtime information for the database queries. Something like /etc/logstash/run.
# PATTERNS_DIR: The full path to the directory to where you stored the GROK patterns for Logstash. Something like /etc/logstash/patterns.
# DATA_CUSTOMER_NAME: Used for identifying an Outsystems customer/tenant amongst multiple customers/tenants on the same Dynatrace tenant.
# DATA_LOCATION_NAME: Used for identifying a location amongst multiple locations for the same customer/tenant.
# DATA_ENVIRONMENT_NAME: Used for identifying an environment amongst multiple environments like dev, qa, prod, etc.
#----------------------------------------------------------------------------------------------------
LAST_RUN_DIR=""
PATTERNS_DIR=""
DATA_CUSTOMER_NAME=""
DATA_LOCATION_NAME=""
DATA_ENVIRONMENT_NAME=""

#----------------------------------------------------------------------------------------------------
# Dynatrace Settings
#----------------------------------------------------------------------------------------------------
# DT_ENDPOINT: The API Endpoint for the logs on the Dynatrace cluster, or the logs endpoint on an activegate. Something like https://abc123456.live.dynatrace.com/api/v2/logs/ingest
# DT_APIKEY: An API Access Key with token scope Log.ingest . Somethink like dt0c01.ABCDEFGHIJKLMNOIP
# DT_VERIFYSSLNONE: boolean to be set to true if you do not want to check the SSL certificate, by default set to false 
#----------------------------------------------------------------------------------------------------

DT_ENDPOINT="" 
DT_APIKEY=""
DT_VERIFYSSLNONE="false"